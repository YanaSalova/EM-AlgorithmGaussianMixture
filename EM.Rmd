---
title: "EM"
output: html_document
date: "2024-04-15"
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```




```{r}
library(mvtnorm)

# Исходные данные
set.seed(123)
d <- rbind(mvtnorm::rmvnorm(500, 
                            c(0,0), 
                            matrix(c(1,0.8,0.8,1), ncol=2)),
           mvtnorm::rmvnorm(500, 
                            c(5,5), 
                            matrix(c(1,-0.8,-0.8,1), ncol=2)))

# Инициализация параметров
mu1 <- c(10, 10)
mu2 <- c(1, 1)

sigma1 <- matrix(c(1, 0, 0, 1), ncol=2)
sigma2 <- matrix(c(1, 0, 0, 1), ncol=2)

pi <- c(0.3, 0.7)  # Веса компонентов смеси


threshold <- 1e-6 # Порог для проверки сходимости
prev_loglik <- -Inf  # Начальное значение 

# EM-алгоритм
for (iter in 1:100) {
  # E-шаг
  probComp1 <- pi[1] * dmvnorm(d, mean=mu1, sigma=sigma1)
  probComp2 <- pi[2] * dmvnorm(d, mean=mu2, sigma=sigma2)

  sum_probabilities <- probComp1 + probComp2
  probComp1 <- probComp1 / sum_probabilities
  probComp2 <- probComp2 / sum_probabilities
  
  
  loglik <- sum(log(sum_probabilities))
  # Проверка сходимости
  if (abs(loglik - prev_loglik) < threshold) {
    cat("EM algorithm has converged at iteration", iter, "\n")
    break
  }
  prev_loglik <- loglik
  
  
  # M-шаг
  mu1 <- colSums(probComp1 * d) / sum(probComp1)
  mu2 <- colSums(probComp2 * d) / sum(probComp2)
  
  cov_result1 <- cov.wt(d, wt = probComp1, method = "ML")
  cov_result2 <- cov.wt(d, wt = probComp2, method = "ML")
  
  sigma1 <- cov_result1$cov * (sum(probComp1) / (sum(probComp1) - 1))  
  sigma2 <- cov_result2$cov * (sum(probComp2) / (sum(probComp2) - 1))
  
  pi <- c(mean(probComp1), mean(probComp2))
}

# Визуализация
x <- seq(min(d[,1]), max(d[,1]), by=.1)
y <- seq(min(d[,2]), max(d[,2]), by=.1)
net1 <- outer(x, y, function(x, y) dmvnorm(cbind(x, y), mu1, sigma1))
net2 <- outer(x, y, function(x, y) dmvnorm(cbind(x, y), mu2, sigma2))

plot(d, main="EM Algorithm for Gaussian Mixture")
contour(x, y, net1, add=TRUE, col='red')
contour(x, y, net2, add=TRUE, col='blue')

```
```{r}
print(paste("Оцененное среднее для компонента 1:", toString(mu1)))
print(paste("Оцененное среднее для компонента 2:", toString(mu2)))
print("Оцененная ковариационная матрица для компонента 1:")
print(sigma1)
print("Оцененная ковариационная матрица для компонента 2:")
print(sigma2)
print(paste("Оцененные веса компонентов смеси:", toString(pi)))

```



```{r}
library(mvtnorm)

# Исходные данные
set.seed(123)
d <- rbind(
  mvtnorm::rmvnorm(500, c(0, 0), matrix(c(1, 0.8, 0.8, 1), ncol=2)),
  mvtnorm::rmvnorm(500, c(5, 5), matrix(c(1, -0.8, -0.8, 1), ncol=2)),
  mvtnorm::rmvnorm(500, c(-4, -4), matrix(c(1, 0.2, 0.2, 1), ncol=2))
)

# Инициализация параметров
mu <- list(c(10, 10), 
           c(1, 1), 
           c(-2, -2))

sigma <- list(matrix(c(1, 0, 0, 1), ncol=2), 
              matrix(c(1, 0, 0, 1), ncol=2), 
              matrix(c(1, 0, 0, 1), ncol=2))

pi <- c(0.1, 0.5, 0.4)  # Веса компонентов смеси


threshold <- 1e-6
prev_loglik <- -Inf

# EM-алгоритм
for (iter in 1:1000) {
  # E-шаг
  probs <- lapply(1:3, function(k) pi[k] * dmvnorm(d,mean=mu[[k]],   sigma=sigma[[k]]))
  sum_probs <- Reduce(`+`, probs)
  posterior_probs  <- lapply(probs, function(p) p / sum_probs)

  
  loglik <- sum(log(sum_probs))
  if (abs(loglik - prev_loglik) < threshold) {
    cat("EM algorithm has converged at iteration", iter, "\n")
    break
  }
  prev_loglik <- loglik
  
  
  # M-шаг
  for (k in 1:3) {
    Nk <- sum(posterior_probs [[k]])
    mu[[k]] <- colSums(posterior_probs [[k]] * d) / Nk

    cov_wt_result <- cov.wt(x = d, wt = posterior_probs [[k]], method = "ML")
    sigma[[k]] <- cov_wt_result$cov * (Nk / (Nk - 1))  
    pi[k] <- Nk / nrow(d)
  }
}


```

```{r}
# Вывод оцененных параметров для каждого компонента
for (k in 1:3) {
  cat(sprintf("Оцененное среднее для компонента %d: %s\n", k, toString(mu[[k]])))
  cat(sprintf("Оцененная ковариационная матрица для компонента %d:\n", k))
  print(sigma[[k]])
}
cat(sprintf("Оцененные веса компонентов смеси: %s\n", toString(pi)))

```
```{r}
plot(d, 
     main="EM Algorithm for Gaussian Mixture")

colors <- c("red", "blue", "green")

for (k in 1:3) {
  mu_k <- mu[[k]]
  sigma_k <- sigma[[k]]
  x_range <- seq(min(d[, 1]) - 1, max(d[, 1]) + 1, length.out = 100)
  y_range <- seq(min(d[, 2]) - 1, max(d[, 2]) + 1, length.out = 100)
  z <- outer(x_range, y_range, function(x, y) dmvnorm(cbind(x, y), mean=mu_k, sigma=sigma_k))
  contour(x_range, y_range, z, add=TRUE, drawlabels=FALSE, col=colors[k])
}

```

